import argparse
import base64
import json
import re
import shutil
import sys
from pathlib import Path
import httpx
from PIL import Image
import numpy as np

BASE_URL = "https://api.a-bly.com/api/v2/screens/SUB_CATEGORY_DEPARTMENT/"
REVIEW_API_URL = "https://api.a-bly.com/api/v2/goods/{sno}/review_summary/"
LEGAL_NOTICE_API_URL = "https://api.a-bly.com/api/v2/goods/{sno}/legal_notice/"
PIPN_INFO_API_URL = "https://api.a-bly.com/api/v2/goods/{sno}/pipn_info/"
DETAIL_API_URL = "https://api.a-bly.com/api/v3/goods/{sno}/detail/"
OPTIONS_API_URL = "https://api.a-bly.com/api/v2/goods/{sno}/options/"
BASIC_API_URL = "https://api.a-bly.com/api/v3/goods/{sno}/basic/"

OUTPUT_DIR = Path("output")
IMAGES_DIR = OUTPUT_DIR / "images"

MIN_PURCHASE_COUNT = 2000
MIN_REVIEW_COUNT = 100
MIN_POSITIVE_PERCENT = 95
MAX_PRODUCTS = 10

# ably ì¹´í…Œê³ ë¦¬ API(overviewCategories) ê¸°ì¤€
# - ì—¬ê¸°ì„œ "ì•„ìš°í„°/ìƒì˜/íŒ¬ì¸ /ìŠ¤ì»¤íŠ¸/ì›í”¼ìŠ¤"ëŠ” depth 1(ìƒìœ„)ì´ê³ ,
# - ì‹¤ì œ ìˆ˜ì§‘ì€ ê·¸ í•˜ìœ„ subCategoryList(depth 2) ê¸°ì¤€ìœ¼ë¡œ ìˆœíšŒí•œë‹¤.
#
# ì£¼ì˜: subCategoryListì˜ item.sno(ì˜ˆ: 926x)ëŠ” í™”ë©´ìš© idì´ê³ ,
# ì‹¤ì œ next_tokenì— ë“¤ì–´ê°€ëŠ” category_snoëŠ” logging.analytics.CATEGORY_SNO ê°’(ì˜ˆ: 293)ì´ë‹¤.
CATEGORIES: dict[str, dict] = {
    "ì•„ìš°í„°": {
        "sno": 7,
        "subcategories": {
            "ê°€ë””ê±´": 16,
            "ìì¼“": 293,
            "ì§‘ì—…/ì í¼": 294,
            "ë°”ëŒë§‰ì´": 497,
            "ì½”íŠ¸": 296,
            "í”Œë¦¬ìŠ¤": 577,
            "ì•¼ìƒ": 496,
            "íŒ¨ë”©": 297,
        },
    },
    "ìƒì˜": {
        "sno": 8,
        "subcategories": {
            "í›„ë“œ": 500,
            "ë§¨íˆ¬ë§¨": 300,
            "ë‹ˆíŠ¸": 299,
            "ì…”ì¸ ": 499,
            "ê¸´ì†Œë§¤í‹°ì…”ì¸ ": 498,
            "ë¸”ë¼ìš°ìŠ¤": 298,
            "ì¡°ë¼": 357,
            "ë°˜ì†Œë§¤í‹°ì…”ì¸ ": 18,
            "ë¯¼ì†Œë§¤": 21,
        },
    },
    "íŒ¬ì¸ ": {
        "sno": 174,
        "subcategories": {
            "ë¡±íŒ¬ì¸ ": 176,
            "ìŠ¬ë™ìŠ¤": 178,
            "ë°ë‹˜": 501,
            "ìˆíŒ¬ì¸ ": 177,
        },
    },
    "ìŠ¤ì»¤íŠ¸": {
        "sno": 203,
        "subcategories": {
            "ë¯¸ë””/ë¡±ìŠ¤ì»¤íŠ¸": 205,
            "ë¯¸ë‹ˆ ìŠ¤ì»¤íŠ¸": 204,
        },
    },
    # API ìƒ ì´ë¦„ì€ "ì›í”¼ìŠ¤/ì„¸íŠ¸" ì´ì§€ë§Œ, ì‚¬ìš© í¸ì˜ìƒ "ì›í”¼ìŠ¤" í‚¤ë¡œ ë‘ 
    "ì›í”¼ìŠ¤": {
        "sno": 10,
        "api_name": "ì›í”¼ìŠ¤/ì„¸íŠ¸",
        "subcategories": {
            "ë¡±ì›í”¼ìŠ¤": 207,
            "íˆ¬í”¼ìŠ¤": 208,
            "ì í”„ìˆ˜íŠ¸": 533,
            "ë¯¸ë‹ˆì›í”¼ìŠ¤": 206,
        },
    },
}


def _build_category_targets(
    category_name: str, subcategory_name: str | None
) -> list[tuple[str, int]]:
    """ìƒìœ„/í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì„ íƒì„ ì‹¤ì œ ìˆ˜ì§‘ íƒ€ê²Ÿ(ë¼ë²¨, category_sno) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    if category_name not in CATEGORIES:
        raise KeyError(f"Unknown category_name: {category_name}")

    cat = CATEGORIES[category_name]
    subs: dict[str, int] = cat.get("subcategories") or {}  # type: ignore[assignment]

    if subcategory_name:
        if subcategory_name not in subs:
            raise KeyError(
                f"Unknown subcategory_name for {category_name}: {subcategory_name}"
            )
        return [(f"{category_name}/{subcategory_name}", int(subs[subcategory_name]))]

    # subcategoriesê°€ ìˆìœ¼ë©´ í•˜ìœ„ë¥¼ ì „ë¶€ ìˆœíšŒ, ì—†ìœ¼ë©´ ìƒìœ„(ìì²´)ë¡œ ìˆ˜ì§‘
    if subs:
        return [(f"{category_name}/{name}", int(sno)) for name, sno in subs.items()]

    return [(category_name, int(cat["sno"]))]


def _build_all_category_targets() -> list[tuple[str, int]]:
    """ëª¨ë“  ìƒìœ„/í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ˜ì§‘ íƒ€ê²Ÿ(ë¼ë²¨, category_sno) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    targets: list[tuple[str, int]] = []
    for category_name, cat in CATEGORIES.items():
        subs: dict[str, int] = cat.get("subcategories") or {}  # type: ignore[assignment]
        if subs:
            targets.extend(
                (f"{category_name}/{name}", int(sno)) for name, sno in subs.items()
            )
        else:
            targets.append((category_name, int(cat["sno"])))
    return targets


def _prompt_choice(title: str, options: list[str]) -> str:
    """í„°ë¯¸ë„ì—ì„œ ë²ˆí˜¸/ì´ë¦„ìœ¼ë¡œ ì„ íƒì„ ë°›ì•„ options ì¤‘ í•˜ë‚˜ë¥¼ ë°˜í™˜."""
    while True:
        print("\n" + title)
        for i, opt in enumerate(options, 1):
            print(f"  {i}. {opt}")
        raw = input("ì„ íƒ(ë²ˆí˜¸ ë˜ëŠ” ì´ë¦„): ").strip()

        if not raw:
            print("  [!] ì…ë ¥ì´ ë¹„ì–´ìˆì–´ìš”. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            continue

        # ë²ˆí˜¸ ì„ íƒ
        if raw.isdigit():
            idx = int(raw)
            if 1 <= idx <= len(options):
                return options[idx - 1]
            print("  [!] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ì–´ìš”. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            continue

        # ì´ë¦„ ì„ íƒ(ì •í™•íˆ ì¼ì¹˜)
        if raw in options:
            return raw

        # ë¶€ë¶„ ì¼ì¹˜ 1ê°œë©´ í—ˆìš©
        matches = [o for o in options if raw in o]
        if len(matches) == 1:
            return matches[0]

        print("  [!] ë§¤ì¹­ë˜ëŠ” í•­ëª©ì´ ì—†ì–´ìš”. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")


def _choose_category_interactive() -> tuple[str | None, str | None, bool]:
    """ì‹¤í–‰ ì‹œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒ(ìƒìœ„/í•˜ìœ„/ì „ì²´)í•˜ëŠ” ì¸í„°ë™í‹°ë¸Œ ë©”ë‰´."""
    top_options = ["ì „ì²´(ì•„ìš°í„°/ìƒì˜/íŒ¬ì¸ /ìŠ¤ì»¤íŠ¸/ì›í”¼ìŠ¤)"] + list(CATEGORIES.keys())
    picked_top = _prompt_choice("ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", top_options)

    if picked_top.startswith("ì „ì²´"):
        return None, None, True

    category_name = picked_top
    cat = CATEGORIES[category_name]
    subs: dict[str, int] = cat.get("subcategories") or {}  # type: ignore[assignment]
    if not subs:
        return category_name, None, False

    sub_options = ["ì „ì²´"] + list(subs.keys())
    picked_sub = _prompt_choice(
        f"í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš” ({category_name}):", sub_options
    )
    if picked_sub == "ì „ì²´":
        return category_name, None, False
    return category_name, picked_sub, False


def _parse_args(argv: list[str]) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Ably ìƒí’ˆ ìˆ˜ì§‘ê¸°")
    p.add_argument("--all", action="store_true", help="ëª¨ë“  ìƒìœ„/í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ˜ì§‘")
    p.add_argument("--category", type=str, help="ìƒìœ„ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ì•„ìš°í„°)")
    p.add_argument(
        "--subcategory",
        type=str,
        help="í•˜ìœ„ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ìì¼“). --categoryì™€ í•¨ê»˜ ì‚¬ìš©",
    )
    p.add_argument(
        "--no-prompt",
        action="store_true",
        help="í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‹¤í–‰ (ì˜µì…˜ ë¯¸ì§€ì • ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)",
    )
    return p.parse_args(argv)


HEADERS = {
    "accept": "application/json, text/plain, */*",
    "accept-language": "ko,en-US;q=0.9,en;q=0.8,ja;q=0.7",
    "cache-control": "no-cache",
    "dnt": "1",
    "origin": "https://m.a-bly.com",
    "pragma": "no-cache",
    "referer": "https://m.a-bly.com/",
    "sec-fetch-dest": "empty",
    "sec-fetch-mode": "cors",
    "sec-fetch-site": "same-site",
    "user-agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1",
    "x-anonymous-token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhbm9ueW1vdXNfaWQiOiI4MDc4MDMxODkiLCJpYXQiOjE3NjgwNjg2MDV9.VLJgodKMn0Mkounf6APU887rLZQAgYWvWy1hRVB3aFE",
    "x-app-version": "0.1.0",
    "x-device-id": "99e795d7-a1b1-44da-b2b5-263f1743b0a2",
    "x-device-type": "MobileWeb",
    "x-web-type": "Web",
}


def create_initial_token(category_sno: int) -> str:
    payload = {
        "l": "DepartmentCategoryRealtimeRankGenerator",
        "p": {"department_type": "CATEGORY", "category_sno": category_sno},
        "d": "CATEGORY",
        "previous_screen_name": "OVERVIEW",
        "category_sno": category_sno,
    }
    return base64.b64encode(json.dumps(payload, ensure_ascii=False).encode()).decode()


def build_product_url(sno: int) -> str:
    return f"https://m.a-bly.com/goods/{sno}"


def extract_products_from_response(data: dict) -> list[dict]:
    products = []
    for component in data.get("components", []):
        item_list = component.get("entity", {}).get("item_list", [])
        for item in item_list:
            if item.get("type") != "GOODS_CARD":
                continue
            item_entity = item.get("item_entity", {})
            item_data = item_entity.get("item", {})
            products.append(
                {
                    "sno": item_data.get("sno"),
                    "name": item_data.get("name"),
                    "sell_count": item_data.get("sell_count", 0),
                    "price": item_data.get("price"),
                    "market_name": item_data.get("market_name"),
                }
            )
    return products


def fetch_review_info(client: httpx.Client, sno: int) -> dict | None:
    try:
        response = client.get(REVIEW_API_URL.format(sno=sno))
        response.raise_for_status()
        data = response.json()
        review = data.get("review", {})
        return {
            "count": review.get("count", 0),
            "positive_percent": review.get("positive_percent", 0),
        }
    except Exception as e:
        print(f"  [!] ë¦¬ë·° ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return None


def fetch_color_info(client: httpx.Client, sno: int) -> str | None:
    """ê³µì‹œì •ë³´ APIì—ì„œ ìƒ‰ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = client.get(LEGAL_NOTICE_API_URL.format(sno=sno))
        response.raise_for_status()
        data = response.json()
        return data.get("color_md")
    except Exception as e:
        print(f"  [!] ìƒ‰ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return None


def fetch_legal_notice_meta(client: httpx.Client, sno: int) -> dict:
    """ê³µì‹œì •ë³´ APIì—ì„œ ë©”íƒ€(ì†Œì¬/ì œì¡°êµ­ ë“±) ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = client.get(LEGAL_NOTICE_API_URL.format(sno=sno))
        response.raise_for_status()
        data = response.json()
        return {
            "color_md": data.get("color_md"),
            "fabric": data.get("fabric"),
            "country": data.get("country"),
        }
    except Exception as e:
        print(f"  [!] ê³µì‹œì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return {}


def fetch_pipn_info_meta(client: httpx.Client, sno: int) -> dict:
    """PIPN Info APIì—ì„œ ë©”íƒ€(ì†Œì¬/ì œì¡°êµ­/ìƒ‰ìƒ ë“±) ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = client.get(PIPN_INFO_API_URL.format(sno=sno))
        response.raise_for_status()
        data = response.json()
        pipn = data.get("product_info_provision_notice", {})
        pipn_data = pipn.get("pipn_data", {})

        fabric = pipn_data.get("fabric_description", {}).get("value")
        country = pipn_data.get("country", {}).get("value")
        color_md = pipn_data.get("color_description", {}).get("value")

        return {
            "color_md": color_md,
            "fabric": fabric,
            "country": country,
        }
    except Exception as e:
        print(f"  [!] PIPN ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return {}


def fetch_product_meta(client: httpx.Client, sno: int) -> dict:
    """PIPN Info API ìš°ì„ , Legal Notice API fallbackìœ¼ë¡œ ë©”íƒ€ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    pipn = fetch_pipn_info_meta(client, sno)
    legal = fetch_legal_notice_meta(client, sno)

    return {
        "color_md": pipn.get("color_md") or legal.get("color_md"),
        "fabric": pipn.get("fabric") or legal.get("fabric"),
        "country": pipn.get("country") or legal.get("country"),
    }


def fetch_basic_meta(client: httpx.Client, sno: int) -> dict:
    """ê¸°ë³¸ì •ë³´ APIì—ì„œ ê°€ê²©/ì¸ë„¤ì¼(cover_images) ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = client.get(BASIC_API_URL.format(sno=sno))
        response.raise_for_status()
        data = response.json()
        goods = data.get("goods", {})
        price_info = goods.get("price_info", {}) or {}
        cover_images = goods.get("cover_images", []) or []
        # cover_imagesëŠ” URL ë¦¬ìŠ¤íŠ¸
        cover_images = [
            u for u in cover_images if isinstance(u, str) and u.startswith("http")
        ]
        return {
            "price_info": {
                "consumer": price_info.get("consumer"),
                "thumbnail_price": price_info.get("thumbnail_price"),
                "discount_rate": price_info.get("discount_rate"),
            },
            "cover_images": cover_images,
        }
    except Exception as e:
        print(f"  [!] ê¸°ë³¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return {}


def fetch_option_colors(client: httpx.Client, sno: int) -> list[str]:
    """ì˜µì…˜ ì •ë³´ APIì—ì„œ 'ì»¬ëŸ¬' ì˜µì…˜ ê°’ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = client.get(OPTIONS_API_URL.format(sno=sno), params={"depth": "1"})
        response.raise_for_status()
        data = response.json()

        # ì‘ë‹µ ì˜ˆì‹œëŠ” { "name": "ì»¬ëŸ¬", "option_components": [...] } í˜•íƒœ
        option_name = data.get("name")
        # ì¼€ì´ìŠ¤: "ì»¬ëŸ¬" / "ìƒ‰ìƒ" / "Color" ë“±
        if option_name not in ("ì»¬ëŸ¬", "ìƒ‰ìƒ", "Color", "COLOR"):
            return []

        colors: list[str] = []
        for opt in data.get("option_components", []):
            name = opt.get("name")
            if isinstance(name, str) and name.strip():
                colors.append(name.strip())

        # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
        seen = set()
        unique: list[str] = []
        for c in colors:
            if c not in seen:
                seen.add(c)
                unique.append(c)
        return unique
    except Exception as e:
        print(f"  [!] ì˜µì…˜ ìƒ‰ìƒ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return []


def clean_image_url(url: str) -> str | None:
    """ì´ë¯¸ì§€ URL ì •ë¦¬ (HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)"""
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    url = url.replace("&quot;", "").replace("\\&quot;", "")
    url = url.replace("&amp;", "&")
    url = url.strip('"').strip("'").strip()

    # ìœ íš¨í•œ URLì¸ì§€ í™•ì¸
    if url.startswith("http://") or url.startswith("https://"):
        return url
    return None


def fetch_detail_images(client: httpx.Client, sno: int) -> list[str]:
    """ìƒì„¸í˜ì´ì§€ APIì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
    try:
        response = client.get(DETAIL_API_URL.format(sno=sno), params={"channel": "0"})
        response.raise_for_status()
        data = response.json()

        images = []
        goods = data.get("goods", {})

        # detail_html_partsì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        for part in goods.get("detail_html_parts", []):
            if part.get("html_part_type") == "DESCRIPTION":
                for content in part.get("contents", []):
                    # img src ì¶”ì¶œ (ë‹¤ì–‘í•œ ì¸ìš©ë¶€í˜¸ íŒ¨í„´ ì²˜ë¦¬)
                    patterns = [
                        r'<img[^>]+src="([^"]+)"',
                        r"<img[^>]+src='([^']+)'",
                        r'<img[^>]+src=\\"([^\\]+)\\"',
                        r"<img[^>]+src=\\&quot;([^&]+)\\&quot;",
                    ]
                    for pattern in patterns:
                        img_urls = re.findall(pattern, content)
                        images.extend(img_urls)

        # ì¤‘ë³µ ì œê±° ë° URL ì •ë¦¬
        unique_images = []
        seen = set()
        for url in images:
            cleaned = clean_image_url(url)
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                unique_images.append(cleaned)

        return unique_images
    except Exception as e:
        print(f"  [!] ìƒì„¸ ì´ë¯¸ì§€ ì¡°íšŒ ì‹¤íŒ¨ (sno={sno}): {e}")
        return []


def download_image(client: httpx.Client, url: str, save_path: Path) -> bool:
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        response = client.get(url, follow_redirects=True)
        response.raise_for_status()
        save_path.write_bytes(response.content)
        return True
    except Exception as e:
        print(f"    [!] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


def download_cover_images(
    client: httpx.Client, sno: int, cover_images: list[str]
) -> list[str]:
    """basic APIì˜ cover_images(ì¸ë„¤ì¼/ëŒ€í‘œì´ë¯¸ì§€) ë‹¤ìš´ë¡œë“œ"""
    if not cover_images:
        return []

    product_dir = IMAGES_DIR / str(sno)
    product_dir.mkdir(parents=True, exist_ok=True)

    downloaded: list[str] = []
    for idx, url in enumerate(cover_images, 1):
        ext = "jpg"
        low = url.lower()
        if ".png" in low:
            ext = "png"
        elif ".webp" in low:
            ext = "webp"
        elif ".gif" in low:
            ext = "gif"

        save_path = product_dir / f"cover_{idx:02d}.{ext}"
        if download_image(client, url, save_path):
            downloaded.append(str(save_path))

    return downloaded


def find_split_points(
    image: Image.Image, threshold: float = 0.98, min_gap: int = 50
) -> list[int]:
    """ì´ë¯¸ì§€ì—ì„œ ë¶„í•  ì§€ì  ì°¾ê¸° (ê· ì¼í•œ ìƒ‰ìƒì˜ ê°€ë¡œì¤„ ê°ì§€)"""
    img_array = np.array(image.convert("RGB"))
    height, width, _ = img_array.shape

    # ê° í–‰ì˜ í”½ì…€ í‘œì¤€í¸ì°¨ ê³„ì‚° (ë‚®ìœ¼ë©´ ê· ì¼í•œ ìƒ‰ìƒ)
    row_std = np.std(img_array, axis=(1, 2))

    # í‘œì¤€í¸ì°¨ê°€ ë‚®ì€ í–‰ ì°¾ê¸° (ê· ì¼í•œ ìƒ‰ìƒ = êµ¬ë¶„ì„ )
    max_std = np.max(row_std)
    if max_std == 0:
        return []
    uniform_rows = row_std < (max_std * (1 - threshold))

    # ì—°ì†ëœ ê· ì¼ í–‰ ê·¸ë£¹ ì°¾ê¸°
    split_points = []
    in_uniform = False
    start = 0

    for i, is_uniform in enumerate(uniform_rows):
        if is_uniform and not in_uniform:
            start = i
            in_uniform = True
        elif not is_uniform and in_uniform:
            mid = (start + i) // 2
            if mid > min_gap and mid < height - min_gap:
                if not split_points or mid - split_points[-1] > min_gap:
                    split_points.append(mid)
            in_uniform = False

    return split_points


def split_image(image_path: Path, min_height: int = 100) -> list[Path]:
    """ì´ë¯¸ì§€ë¥¼ ë¶„í• í•˜ê³  ì €ì¥ (ì›ë³¸ íŒŒì¼ ëŒ€ì²´)"""
    try:
        with Image.open(image_path) as image:
            width, height = image.size

            # ì„¸ë¡œë¡œ ê¸´ ì´ë¯¸ì§€ê°€ ì•„ë‹ˆë©´ ë¶„í•  ë¶ˆí•„ìš”
            if height < width * 1.5:
                return [image_path]

            split_points = find_split_points(image)
            if not split_points:
                return [image_path]

            # ë¶„í•  ì§€ì ìœ¼ë¡œ ì´ë¯¸ì§€ ìë¥´ê¸°
            saved_paths: list[Path] = []
            points = [0] + split_points + [height]
            stem = image_path.stem
            suffix = image_path.suffix.lower()
            parent = image_path.parent

            for i in range(len(points) - 1):
                top = points[i]
                bottom = points[i + 1]

                if bottom - top < min_height:
                    continue

                cropped = image.crop((0, top, width, bottom))

                # JPEGëŠ” RGBA ì§€ì› ì•ˆí•¨ â†’ RGBë¡œ ë³€í™˜
                if suffix in [".jpg", ".jpeg"] and cropped.mode == "RGBA":
                    # í°ìƒ‰ ë°°ê²½ì— í•©ì„±
                    background = Image.new("RGB", cropped.size, (255, 255, 255))
                    background.paste(cropped, mask=cropped.split()[3])
                    cropped = background

                output_path = parent / f"{stem}_{i + 1:02d}{suffix}"
                cropped.save(output_path)
                saved_paths.append(output_path)

        # ë¶„í•  ì„±ê³µì‹œ: ì›ë³¸ì„ ë°±ì—…ìœ¼ë¡œ ë³´ê´€í•œ ë’¤ ì›ë³¸ ì‚­ì œ
        if len(saved_paths) > 1:
            backup_path = (
                image_path.parent / f"{image_path.stem}_original{image_path.suffix}"
            )
            try:
                if not backup_path.exists():
                    shutil.copy2(image_path, backup_path)
            except Exception:
                # ë°±ì—… ë³µì‚¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ì„ ì‚­ì œí•˜ë©´ ì•ˆ ë¨
                print(f"    [!] ì›ë³¸ ë°±ì—… ì‹¤íŒ¨: {image_path} (ì›ë³¸ ìœ ì§€)")
            else:
                # ë°±ì—…ì´ ìˆìœ¼ë©´ ì›ë³¸ ì‚­ì œ
                if backup_path.exists():
                    image_path.unlink()

        return saved_paths
    except Exception:
        return [image_path]


def download_product_images(client: httpx.Client, product: dict) -> list[str]:
    """ìƒí’ˆì˜ ìƒì„¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¶„í• """
    sno = product["sno"]
    product_dir = IMAGES_DIR / str(sno)
    product_dir.mkdir(parents=True, exist_ok=True)

    images = fetch_detail_images(client, sno)
    all_images = []

    for idx, url in enumerate(images):
        ext = "jpg"
        if ".png" in url.lower():
            ext = "png"
        elif ".gif" in url.lower():
            ext = "gif"
        elif ".webp" in url.lower():
            ext = "webp"

        filename = f"{idx + 1:03d}.{ext}"
        save_path = product_dir / filename

        if download_image(client, url, save_path):
            # ì´ë¯¸ì§€ ë¶„í•  ì‹œë„
            split_paths = split_image(save_path)
            if len(split_paths) > 1:
                print(f"    âœ‚ï¸ {filename} â†’ {len(split_paths)}ê°œë¡œ ë¶„í• ")
            all_images.extend(str(p) for p in split_paths)

    return all_images


def write_product_metadata(product: dict) -> None:
    """ë¶„ë¥˜ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìƒí’ˆ ë©”íƒ€ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ í´ë”ì— ì €ì¥"""
    sno = product["sno"]
    product_dir = IMAGES_DIR / str(sno)
    product_dir.mkdir(parents=True, exist_ok=True)

    meta = {
        "sno": sno,
        "name": product.get("name"),
        "category": product.get("category"),
        "market_name": product.get("market_name"),
        "url": product.get("url"),
        # ì˜µì…˜ ê¸°ë°˜ ìƒ‰ìƒ(ì •ë‹µ ì†ŒìŠ¤)
        "option_colors": product.get("option_colors") or [],
        # ì°¸ê³ : ê³µì‹œì •ë³´ ìƒ‰ìƒ(ì½¤ë§ˆ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ)
        "legal_notice_colors": product.get("colors"),
        # ê°€ê²© ì •ë³´ (basic)
        "price_info": product.get("price_info"),
        # ì†Œì¬/ì œì¡°êµ­ (legal_notice)
        "fabric": product.get("fabric"),
        "country": product.get("country"),
        # ì¸ë„¤ì¼ URL (basic)
        "cover_images": product.get("cover_images") or [],
        # ì°¸ê³ ìš©
        "sell_count": product.get("sell_count"),
        "review_count": product.get("review_count"),
        "positive_percent": product.get("positive_percent"),
    }

    meta_path = product_dir / "meta.json"
    meta_path.write_text(
        json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8"
    )


def fetch_products_by_category(
    category_sno: int, category_name: str = ""
) -> list[dict]:
    found_products: list[dict] = []
    checked_snos: set[int] = set()
    next_token = create_initial_token(category_sno)

    print(f"\n{'=' * 50}")
    print(f"ì¹´í…Œê³ ë¦¬: {category_name} (sno={category_sno})")
    print(f"{'=' * 50}")

    with httpx.Client(headers=HEADERS, timeout=30) as client:
        while len(found_products) < MAX_PRODUCTS:
            params = {
                "next_token": next_token,
                "category_list[]": str(category_sno),
                "sorting_type": "POPULAR",
            }

            response = client.get(BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            products = extract_products_from_response(data)

            for product in products:
                sno = product["sno"]
                if sno in checked_snos:
                    continue
                checked_snos.add(sno)

                if product["sell_count"] < MIN_PURCHASE_COUNT:
                    continue

                print(
                    f"ê²€ì‚¬ì¤‘: {product['name'][:40]}... ({product['sell_count']:,}ê°œ êµ¬ë§¤)"
                )

                review = fetch_review_info(client, sno)
                if not review:
                    continue

                if review["count"] < MIN_REVIEW_COUNT:
                    print(
                        f"  âŒ ë¦¬ë·° ìˆ˜ ë¶€ì¡±: {review['count']}ê°œ < {MIN_REVIEW_COUNT}ê°œ"
                    )
                    continue

                if review["positive_percent"] < MIN_POSITIVE_PERCENT:
                    print(
                        f"  âŒ ê¸ì •ë¥  ë¶€ì¡±: {review['positive_percent']}% < {MIN_POSITIVE_PERCENT}%"
                    )
                    continue

                product["url"] = build_product_url(sno)
                product["review_count"] = review["count"]
                product["positive_percent"] = review["positive_percent"]
                product["category"] = category_name
                found_products.append(product)

                print(
                    f"  âœ… [{len(found_products)}/{MAX_PRODUCTS}] ë¦¬ë·° {review['count']}ê°œ, ê¸ì •ë¥  {review['positive_percent']}%"
                )

                if len(found_products) >= MAX_PRODUCTS:
                    break

            if len(found_products) >= MAX_PRODUCTS:
                break

            next_token = data.get("next_token")
            if not next_token:
                print("No more pages")
                break

    return found_products


def enrich_product_details(products: list[dict]) -> None:
    """ìƒí’ˆ ìƒì„¸ ì •ë³´(ìƒ‰ìƒ, ì´ë¯¸ì§€) ì¶”ê°€"""
    print(f"\n{'=' * 50}")
    print("ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    print(f"{'=' * 50}")

    with httpx.Client(headers=HEADERS, timeout=60) as client:
        for i, product in enumerate(products, 1):
            sno = product["sno"]
            print(f"\n[{i}/{len(products)}] {product['name'][:40]}...")

            # ê³µì‹œì •ë³´(ìƒ‰ìƒ/ì†Œì¬/ì œì¡°êµ­) - PIPN ìš°ì„ , Legal Notice fallback
            meta = fetch_product_meta(client, sno)
            product["colors"] = meta.get("color_md")
            product["fabric"] = meta.get("fabric")
            product["country"] = meta.get("country")
            if product.get("colors"):
                print(f"  ğŸ¨ ìƒ‰ìƒ(ê³µì‹œ): {product['colors']}")
            if product.get("fabric"):
                print(f"  ğŸ§µ ì†Œì¬(í˜¼ìš©ë¥ ): {product['fabric']}")
            if product.get("country"):
                print(f"  ğŸŒ ì œì¡°êµ­: {product['country']}")

            # ì˜µì…˜(ì»¬ëŸ¬) ì •ë³´: ë¶„ë¥˜ì˜ ì •ë‹µ ì†ŒìŠ¤
            option_colors = fetch_option_colors(client, sno)
            product["option_colors"] = option_colors
            if option_colors:
                print(f"  ğŸ¨ ì˜µì…˜ ìƒ‰ìƒ: {', '.join(option_colors)}")

            # ê¸°ë³¸ì •ë³´(ê°€ê²©/ì¸ë„¤ì¼)
            basic = fetch_basic_meta(client, sno)
            product["price_info"] = basic.get("price_info")
            product["cover_images"] = basic.get("cover_images") or []
            if product.get("price_info"):
                pi = product["price_info"] or {}
                cp = pi.get("consumer")
                tp = pi.get("thumbnail_price")
                dr = pi.get("discount_rate")
                msg = []
                if tp is not None:
                    msg.append(f"{tp:,}ì›")
                if dr is not None:
                    msg.append(f"{dr}%")
                if cp is not None:
                    msg.append(f"(ì •ê°€ {cp:,}ì›)")
                if msg:
                    print(f"  ğŸ’° ê°€ê²©: {' '.join(msg)}")

            # ì¸ë„¤ì¼(cover_images) ë‹¤ìš´ë¡œë“œ
            cover_local = download_cover_images(
                client, sno, product.get("cover_images") or []
            )
            product["cover_images_local"] = cover_local
            if cover_local:
                print(f"  ğŸ–¼ï¸ ì¸ë„¤ì¼: {len(cover_local)}ê°œ ë‹¤ìš´ë¡œë“œ")

            # ë¶„ë¥˜ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ë©”íƒ€ë°ì´í„° ì €ì¥
            write_product_metadata(product)

            # ìƒì„¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            downloaded = download_product_images(client, product)
            product["images"] = downloaded
            print(f"  ğŸ“· ì´ë¯¸ì§€: {len(downloaded)}ê°œ ë‹¤ìš´ë¡œë“œ")


def save_results(products: list[dict]) -> None:
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    output_file = OUTPUT_DIR / "products.json"

    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    for product in products:
        if "images" in product:
            product["images"] = [
                str(Path(p).relative_to(OUTPUT_DIR)) for p in product["images"]
            ]

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")


def main() -> None:
    args = _parse_args(sys.argv[1:])

    category_name: str | None = args.category
    subcategory_name: str | None = args.subcategory
    all_categories: bool = bool(args.all)

    if subcategory_name and not category_name:
        raise SystemExit("--subcategoryëŠ” --categoryì™€ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•´ìš”.")

    # ì˜µì…˜ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ê³ , í”„ë¡¬í”„íŠ¸ í—ˆìš©ì´ë©´ ì‹¤í–‰ ì‹œ ì„ íƒ
    if not args.no_prompt and not all_categories and not category_name:
        category_name, subcategory_name, all_categories = _choose_category_interactive()

    # ì—¬ì „íˆ ì•„ë¬´ ê²ƒë„ ì•ˆ ì •í•´ì¡Œìœ¼ë©´ ê¸°ë³¸ê°’
    if not all_categories and not category_name:
        category_name = "ì•„ìš°í„°"

    targets = (
        _build_all_category_targets()
        if all_categories
        else _build_category_targets(category_name, subcategory_name)  # type: ignore[arg-type]
    )

    # 1. ìƒí’ˆ ê²€ìƒ‰ (í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë“¤ì„ ìˆœíšŒ)
    found_products: list[dict] = []
    for label, category_sno in targets:
        found_products.extend(fetch_products_by_category(category_sno, label))

    # ì¤‘ë³µ ì œê±°(ìƒí’ˆ sno ê¸°ì¤€, ìˆœì„œ ìœ ì§€)
    unique: list[dict] = []
    seen: set[int] = set()
    for p in found_products:
        sno = p.get("sno")
        if not isinstance(sno, int):
            continue
        if sno in seen:
            continue
        seen.add(sno)
        unique.append(p)
    found_products = unique

    if not found_products:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ìƒ‰ìƒ + ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ)
    enrich_product_details(found_products)

    # 3. ê²°ê³¼ ì €ì¥
    save_results(found_products)

    # 4. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 50)
    print(f"ìµœì¢… ê²°ê³¼: {len(found_products)}ê°œ ìƒí’ˆ")
    print("=" * 50)

    for i, product in enumerate(found_products, 1):
        print(f"\n{i}. {product['name']}")
        print(
            f"   êµ¬ë§¤: {product['sell_count']:,}ê°œ | ë¦¬ë·°: {product['review_count']}ê°œ | ê¸ì •ë¥ : {product['positive_percent']}%"
        )
        print(f"   ìƒ‰ìƒ: {product.get('option_colors', 'N/A')}")
        print(f"   ì´ë¯¸ì§€: {len(product.get('images', []))}ê°œ")
        print(f"   {product['url']}")


if __name__ == "__main__":
    main()
